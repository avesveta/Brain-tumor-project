{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Set Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 137\n",
    "\n",
    "MIN_WIDTH = 29\n",
    "MAX_WIDTH = 215\n",
    "\n",
    "MIN_HEIGHT = 45\n",
    "MAX_HEIGHT = 239\n",
    "\n",
    "MIN_DEPTH = 15\n",
    "MAX_DEPTH = 143"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../raw_data/Grade_ID_nii.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39m\"\u001b[39;49m\u001b[39m../raw_data/Grade_ID_nii.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mGrade\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mGrade\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m x \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mHGG\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/brain-tumor-project/lib/python3.10/site-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/brain-tumor-project/lib/python3.10/site-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../raw_data/Grade_ID_nii.pkl'"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../raw_data/Grade_ID_nii.pkl\")\n",
    "\n",
    "df['Grade'] = df['Grade'].apply(lambda x: 0 if x == 'HGG' else 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: EDA before slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 369\n",
      "Negative examples: (293, 3)\n",
      "Positive examples: (76, 3)\n",
      "\n",
      "Single example Shape:\n",
      "Height: 240\n",
      "Width: 240\n",
      "Depth: 155\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of samples: {df['nii'].shape[0]}\")\n",
    "print(f\"Negative examples: {df[df['Grade'] == 0].shape}\")\n",
    "print(f\"Positive examples: {df[df['Grade'] == 1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to calculate crop parameters for depth\n",
    "non_zero = []\n",
    "min_value = []\n",
    "max_value = []\n",
    "\n",
    "for n_image in range(df['nii'].shape[0]):\n",
    "    image = df['nii'][n_image]\n",
    "    image_depth_sum = [np.sum(image[:,:,i]) for i in range(image.shape[2])]\n",
    "    non_zero.append(np.nonzero(image_depth_sum)[0].shape[0])\n",
    "    min_value.append(np.min(np.nonzero(image_depth_sum)[0]))\n",
    "    max_value.append(np.max(np.nonzero(image_depth_sum)[0]))\n",
    "    plt.plot(image_depth_sum)\n",
    "plt.show()\n",
    "# here we calculate limits for the depth parameter, but similarly \n",
    "# limits can be found for other parameters as well\n",
    "print(f\"Defined limits: min - {np.min(min_value)}; max - {np.max(max_value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to calculate crop parameters for depth\n",
    "non_zero = []\n",
    "min_value = []\n",
    "max_value = []\n",
    "\n",
    "for n_image in range(df['nii'].shape[0]):\n",
    "    image = df['nii'][n_image]\n",
    "    image_depth_sum = [np.sum(image[:,:,i]) for i in range(image.shape[2])]\n",
    "    non_zero.append(np.nonzero(image_depth_sum)[0].shape[0])\n",
    "    min_value.append(np.min(np.nonzero(image_depth_sum)[0]))\n",
    "    max_value.append(np.max(np.nonzero(image_depth_sum)[0]))\n",
    "    plt.plot(image_depth_sum)\n",
    "plt.show()\n",
    "# here we calculate limits for the depth parameter, but similarly \n",
    "# limits can be found for other parameters as well\n",
    "print(f\"Defined limits: min - {np.min(min_value)}; max - {np.max(max_value)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Crop Images and run Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop images\n",
    "df['nii'] = df['nii'].apply(lambda x: np.array(x[MIN_HEIGHT:MAX_HEIGHT,MIN_WIDTH:MAX_WIDTH,MIN_DEPTH:MAX_DEPTH]))\n",
    "X = df['nii']\n",
    "y = df['Grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([np.array(val) for val in X])\n",
    "X = X.reshape(len(X), X[0].shape[0], X[0].shape[1], X[0].shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image(X, y, i):\n",
    "    angles = [-30, -20, -15, -10, -5, 5, 10, 15, 20, 30]\n",
    "    angle = random.choice(angles)\n",
    "    rotated_example = ndimage.rotate(X[i], angle, reshape=False)\n",
    "    X = np.append(X, np.expand_dims(rotated_example, axis=0), axis=0)\n",
    "    y = y.append(pd.Series([y[i]]), ignore_index=True)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_79090/1348074226.py:6: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y = y.append(pd.Series([y[i]]), ignore_index=True) # append label\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    if y[i] == 0:\n",
    "        pass\n",
    "    else:\n",
    "        X,y = rotate_image(X, y, i)\n",
    "        X,y = rotate_image(X, y, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(416, 194, 186, 128, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    234\n",
       "1    182\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(input_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units=64, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=0.0001), \n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_29 (Conv3D)           (None, 192, 184, 126, 64) 1792      \n",
      "_________________________________________________________________\n",
      "max_pooling3d_27 (MaxPooling (None, 96, 92, 63, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 96, 92, 63, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_30 (Conv3D)           (None, 94, 90, 61, 64)    110656    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_28 (MaxPooling (None, 47, 45, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 47, 45, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv3d_31 (Conv3D)           (None, 45, 43, 28, 128)   221312    \n",
      "_________________________________________________________________\n",
      "max_pooling3d_29 (MaxPooling (None, 22, 21, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 22, 21, 14, 128)   512       \n",
      "_________________________________________________________________\n",
      "global_average_pooling3d_8 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 401,345\n",
      "Trainable params: 400,833\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = initialize_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Size of X_train: 7.685603328 Gb\n"
     ]
    }
   ],
   "source": [
    "print(f\" Size of X_train: {(X_train.size * X_train.itemsize) / 1e9} Gb\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 22:59:11.111464: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7685603328 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "208/208 [==============================] - 174s 750ms/step - loss: 0.6184 - accuracy: 0.6766 - val_loss: 16.1681 - val_accuracy: 0.4381\n",
      "Epoch 2/30\n",
      "208/208 [==============================] - 148s 712ms/step - loss: 0.4696 - accuracy: 0.7747 - val_loss: 19.9116 - val_accuracy: 0.4381\n",
      "Epoch 3/30\n",
      "208/208 [==============================] - 148s 710ms/step - loss: 0.5115 - accuracy: 0.7473 - val_loss: 17.5303 - val_accuracy: 0.5619\n",
      "Epoch 4/30\n",
      "208/208 [==============================] - 148s 710ms/step - loss: 0.4792 - accuracy: 0.7648 - val_loss: 20.1856 - val_accuracy: 0.4381\n",
      "Epoch 5/30\n",
      " 38/208 [====>.........................] - ETA: 1:51 - loss: 0.3645 - accuracy: 0.8828"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[93], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[39m=\u001b[39m EarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train,\n\u001b[1;32m      3\u001b[0m                         epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m                         batch_size \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m                         callbacks \u001b[39m=\u001b[39;49m [es],\n\u001b[1;32m      6\u001b[0m                         validation_data\u001b[39m=\u001b[39;49m(X_test, y_test),\n\u001b[1;32m      7\u001b[0m                         shuffle \u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      8\u001b[0m                         verbose \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1105\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs  \u001b[39m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1105\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1106\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1107\u001b[0m   \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:454\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \n\u001b[1;32m    449\u001b[0m \u001b[39mArguments:\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 454\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m'\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m'\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:296\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    295\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mend\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 296\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    298\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(hook))\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:316\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m   batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    314\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 316\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    319\u001b[0m   end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:356\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[1;32m    355\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(callback, \u001b[39m'\u001b[39m\u001b[39m_supports_tf_logs\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 356\u001b[0m   hook(batch, logs)\n\u001b[1;32m    357\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m   \u001b[39mif\u001b[39;00m numpy_logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Only convert once.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1020\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1019\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1020\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/callbacks.py:1084\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1082\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1083\u001b[0m   \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1084\u001b[0m   logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49mto_numpy_or_python_type(logs)\n\u001b[1;32m   1085\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:514\u001b[0m, in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t  \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[0;32m--> 514\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/util/nest.py:659\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    655\u001b[0m flat_structure \u001b[39m=\u001b[39m (flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m    656\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m    658\u001b[0m \u001b[39mreturn\u001b[39;00m pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0m     structure[\u001b[39m0\u001b[39m], [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m    660\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites)\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/keras/utils/tf_utils.py:510\u001b[0m, in \u001b[0;36mto_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    509\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, ops\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 510\u001b[0m     x \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    511\u001b[0m     \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(x) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    512\u001b[0m   \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1071\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \n\u001b[1;32m   1050\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1070\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m-> 1071\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu-venv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1037\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1036\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m   1038\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     six\u001b[39m.\u001b[39mraise_from(core\u001b[39m.\u001b[39m_status_to_exception(e\u001b[39m.\u001b[39mcode, e\u001b[39m.\u001b[39mmessage), \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "    \n",
    "history = model.fit(X_train, y_train,\n",
    "                        epochs=30,\n",
    "                        batch_size=2,\n",
    "                        callbacks=[es],\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        shuffle=True,\n",
    "                        verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the learning curve\n",
    "def plot_loss(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=1)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.2)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.2)    \n",
    "    \n",
    "    ax2.plot(history.history['accuracy'])\n",
    "    ax2.plot(history.history['val_accuracy'])\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=1)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.2)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.2)    \n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
