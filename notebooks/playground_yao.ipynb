{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_logic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pylab \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mml_logic\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m load_nii_from_gcp\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m storage\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ml_logic'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "from nibabel import nifti1\n",
    "import nibabel as nib\n",
    "from matplotlib import pylab as plt\n",
    "import matplotlib\n",
    "from ml_logic.data import load_nii_from_gcp\n",
    "\n",
    "from google.cloud import storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# make a lockal cach folder\n",
    "directory = \"cache\" \n",
    "\n",
    "#need to change the '/home/yaoyx001/code/' to your folder location\n",
    "parent_dir = \"/home/yaoyx001/code/\" \n",
    "# Path\n",
    "path = os.path.join(parent_dir, directory)\n",
    "  \n",
    "# Create the directory\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(\"Directory '% s' created\" % directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#check the connection to GCP\n",
    "client = storage.Client()\n",
    "\n",
    "#get the Bucket Name from .env\n",
    "bucket_name = 'row_data_bucket'\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "blob_name='BraTS20_Training_001_seg.nii'\n",
    "#get the blob(file)\n",
    "blob = bucket.blob(blob_name)\n",
    "\n",
    "cache_file = os.path.join(path, blob_name)\n",
    "#save the file in cache_folder\n",
    "\n",
    "if not os.path.isfile(cache_file):\n",
    "    blob.download_to_filename(cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "\n",
    "client = storage.Client()\n",
    "\n",
    "#get the Bucket Name from .env\n",
    "bucket_name = 'row_data_bucket'\n",
    "#set bucket\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "#give the blob_name that you want to access\n",
    "blob_name='BraTS20_Training_005_seg.nii'\n",
    "#get the blob(file)\n",
    "blob = bucket.blob(blob_name)\n",
    "# make a lockal cach folder\n",
    "directory = \"cache\" \n",
    "parent_dir = \"/home/yaoyx001/code/\" #need to change the yaoyx001 to your username\n",
    "# Path\n",
    "path = os.path.join(parent_dir, directory)\n",
    "  \n",
    "# Create the directory\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    print(\"Directory '% s' created\" % directory)\n",
    "\n",
    "cache_file = os.path.join(path, blob_name)\n",
    "#save the file in cache_folder\n",
    "\n",
    "if not os.path.isfile(cache_file):\n",
    "    blob.download_to_filename(cache_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_nii_from_gcp2\u001b[39m(filename:\u001b[39mstr\u001b[39m,cache_folder_path:path):\n\u001b[1;32m      2\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcloud\u001b[39;00m \u001b[39mimport\u001b[39;00m storage\n\u001b[1;32m      3\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"
     ]
    }
   ],
   "source": [
    "def load_nii_from_gcp2(filename:str,cache_folder_path:path):\n",
    "    from google.cloud import storage\n",
    "    import os\n",
    "    import nibabel as nib\n",
    "    \n",
    "    \n",
    "    #make the connection to GCP\n",
    "    client = storage.Client()\n",
    "    #get the Bucket Name from .env\n",
    "    bucket_name = 'row_data_bucket'\n",
    "    #set bucket\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    #give the blob_name that you want to access\n",
    "    blob_name= filename\n",
    "    #get the blob(file)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    \n",
    "    cache_file_path = os.path.join(cache_folder_path, blob_name)\n",
    "    #save the file in cache_folder\n",
    "    if not os.path.isfile(cache_file_path):\n",
    "        blob.download_to_filename(cache_file_path)\n",
    "        \n",
    "    img =nib.load(cache_file_path)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_nii_from_gcp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#load the \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m img \u001b[39m=\u001b[39m load_nii_from_gcp(\u001b[39m'\u001b[39m\u001b[39mBraTS20_Training_006_seg.nii\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39m/home/yaoyx001/code/cache\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# print the img\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(img)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_nii_from_gcp' is not defined"
     ]
    }
   ],
   "source": [
    "#load the \n",
    "img = load_nii_from_gcp('BraTS20_Training_006_seg.nii',\"/home/yaoyx001/code/cache\")\n",
    "\n",
    "# print the img\n",
    "print(img)\n",
    "print(img.dataobj.shape)\n",
    "\n",
    "\n",
    "# 由文件本身维度确定，可能是3维，也可能是4维 \n",
    "width,height,queue=img.dataobj.shape\n",
    "  \n",
    "num = 1\n",
    "for i in range(0,queue,10):\n",
    " \n",
    "    img_arr = img.dataobj[:,:,i]\n",
    "    plt.subplot(5,4,num)\n",
    "    plt.imshow(img_arr,cmap='gray')\n",
    "    num +=1\n",
    " \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    # The ID of your GCS bucket\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # The path to your file to upload\n",
    "    # source_file_name = \"local/path/to/file\"\n",
    "    # The ID of your GCS object\n",
    "    # destination_blob_name = \"storage-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    # Optional: set a generation-match precondition to avoid potential race conditions\n",
    "    # and data corruptions. The request to upload is aborted if the object's\n",
    "    # generation number does not match your precondition. For a destination\n",
    "    # object that does not yet exist, set the if_generation_match precondition to 0.\n",
    "    # If the destination object already exists in your bucket, set instead a\n",
    "    # generation-match precondition using its generation number.\n",
    "    generation_match_precondition = 0\n",
    "\n",
    "    blob.upload_from_filename(source_file_name, if_generation_match=generation_match_precondition)\n",
    "\n",
    "    print(\n",
    "        f\"File {source_file_name} uploaded to {destination_blob_name}.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Grade_ID_nii.pkl uploaded to Grade_ID_nii.pkl.\n"
     ]
    }
   ],
   "source": [
    "upload_blob(bucket_name='row_data_bucket', source_file_name=\"Grade_ID_nii.pkl\",destination_blob_name=\"Grade_ID_nii.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading nii from cloud as save it in raw_data folder\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(pkl_file):\n\u001b[1;32m     10\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpkl_file\u001b[39m}\u001b[39;00m\u001b[39m is saved into raw_data\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(pkl_file)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/brain-tumor-project/lib/python3.10/site-packages/pandas/io/pickle.py:208\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings(record\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    206\u001b[0m         \u001b[39m# We want to silence any warnings about, e.g. moved modules.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mWarning\u001b[39;00m)\n\u001b[0;32m--> 208\u001b[0m         \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39;49mload(handles\u001b[39m.\u001b[39;49mhandle)\n\u001b[1;32m    209\u001b[0m \u001b[39mexcept\u001b[39;00m excs_to_catch:\n\u001b[1;32m    210\u001b[0m     \u001b[39m# e.g.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[39m#  \"No module named 'pandas.core.sparse.series'\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[39m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[39mreturn\u001b[39;00m pc\u001b[39m.\u001b[39mload(handles\u001b[39m.\u001b[39mhandle, encoding\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "channel = 't1'\n",
    "#load nii file from cloud or local cach folder and save it as pkl in /raw_data\n",
    "\n",
    "pkl_file= f\"raw_data/Grade_ID_{channel}_nii.pkl\"\n",
    "print('loading nii from cloud as save it in raw_data folder')\n",
    "if not os.path.isfile(pkl_file):\n",
    "    \n",
    "    print(f'{pkl_file} is saved into raw_data')\n",
    "\n",
    "df = pd.read_pickle(pkl_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-tumor-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
