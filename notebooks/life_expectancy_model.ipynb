{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing a model architecture for life expectancy classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports go here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import nibabel as nib\n",
    "import scikeras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## empty for now for data import or whatever\n",
    "#need two X's: X_nii for neuroimaging and X_age for age\n",
    "#for first optional model X_nii and X_age can be united into X_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model architecture - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (240, 240, 155, 1) ##probably we need to change it because of age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we need 1 kernel as we have 1 label for segmentation, kernel size = 3x3x3?\n",
    "# https://stackoverflow.com/questions/42556919/adding-a-variable-into-keras-tensorflow-cnn-dense-layer\n",
    "# https://stackoverflow.com/questions/43196636/how-to-concatenate-two-layers-in-keras\n",
    "#initialize model\n",
    "\n",
    "def initialize_model(dropout = 0.5, dense_1 = 50, \\\n",
    "    learning_rate = 0.01, kernel_size=(3,3,3), pool_size = (2,2,2)):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add convo layers to the model\n",
    "    model.add(Conv3D(32, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Conv3D(64, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Conv3D(128, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    \n",
    "    #Add a flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Add dense levels\n",
    "    model.add(Dense(dense_1, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    \n",
    "    #maybe ADD AGE here for the second model\n",
    "    # Merge the output of the convNet with your added features by concatenation\n",
    "    model_age_input = Sequential()\n",
    "    model_age_input.add(Dense(1, input_shape=(1,), activation='relu'))\n",
    "    \n",
    "    # concatenate two layers\n",
    "    model_with_age = Concatenate([model, model_age_input])\n",
    "    \n",
    "    #Add layer with activation\n",
    "    model_with_age.add(Dense(16, activation='relu'))\n",
    "    model_with_age.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    #Model compilation\n",
    "    optim=Adam(learning_rate=learning_rate)\n",
    "    model_with_age.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optim,\n",
    "                  metrics = ['accuracy'])\n",
    "    return model_with_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate a model\n",
    "model_seg = initialize_model()\n",
    "model_seg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#better to write it down as a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline model score\n",
    "es = EarlyStopping(patience=3, restore_best_weights = True)\n",
    "history = model_seg.fit(X_train, y_train,\n",
    "                        epochs = 30,\n",
    "                        batch_size = 16,\n",
    "                        callbacks = [es],\n",
    "                        validation_split = 0.2,\n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the learning curve\n",
    "def plot_loss(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(13,4))\n",
    "    ax1.plot(history.history['loss'])\n",
    "    ax1.plot(history.history['val_loss'])\n",
    "    ax1.set_title('Model loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylim(ymin=0, ymax=200)\n",
    "    ax1.legend(['Train', 'Validation'], loc='best')\n",
    "    ax1.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax1.grid(axis=\"y\",linewidth=0.5)    \n",
    "    \n",
    "    ax2.plot(history.history['accuracy'])\n",
    "    ax2.plot(history.history['val_accuracy'])\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylim(ymin=0, ymax=20)\n",
    "    ax2.legend(['Train', 'Validation'], loc='best')\n",
    "    ax2.grid(axis=\"x\",linewidth=0.5)\n",
    "    ax2.grid(axis=\"y\",linewidth=0.5)    \n",
    "\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_estimator = KerasClassifier(build_fn = initialize_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Pipeline([('kc', keras_estimator)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters tuning\n",
    "# Define the hyperparameters\n",
    "param_grid = {\n",
    "    'kc__dense_1': [20, 30, 50, 100],\n",
    "    'kc__kernel_size': [(2,2,2),(3,3,3), (5,5,5), (7,7,7)],\n",
    "    'kc__pool_size': [(2,2,2),(3,3,3)],\n",
    "    'kc__batch_size':[8, 16, 32],\n",
    "    'kc__dropout': [0.5, 0.4, 0.3, 0.2, 0.1, 0],\n",
    "    'kc__learning_rate': [0.001, 0.01, 0.1]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_splits = 5\n",
    "grid = GridSearchCV(estimator=estimator,  \n",
    "                    n_jobs=-1, \n",
    "                    verbose=1,\n",
    "                    return_train_score=True,\n",
    "                    cv=kfold_splits,  #StratifiedKFold(n_splits=kfold_splits, shuffle=True)\n",
    "                    param_grid=param_grid,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X, y) #callbacks=[tbCallBack]\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction with the final model \n",
    "model_seg.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second model architecture  option in case the first approach doesn't work\n",
    "def build_model_nii(dropout = 0.5, dense_1 = 50, \\\n",
    "    learning_rate = 0.01, kernel_size=(3,3,3), pool_size = (2,2,2)):\n",
    "    model = Sequential()\n",
    "    #Add convo layers to the model\n",
    "    model.add(Conv3D(32, kernel_size=kernel_size, activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Conv3D(64, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    model.add(Conv3D(128, kernel_size=kernel_size, activation='relu'))\n",
    "    model.add(MaxPooling3D(pool_size=pool_size))\n",
    "    \n",
    "    #Add a flatten layer\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #Add dense levels\n",
    "    model.add(Dense(dense_1, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    optim=Adam(learning_rate=0.01)\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optim,\n",
    "                  metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "model_nii = build_model_nii()\n",
    "model_nii.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(patience=3, restore_best_weights = True)\n",
    "\n",
    "model_nii = build_model_nii()\n",
    "model_nii.fit(X_nii, y, \n",
    "          validation_split=0.3,\n",
    "          epochs=30, \n",
    "          batch_size=16,\n",
    "          callbacks=[es]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_age():\n",
    "    input_age = Input(shape=(X_age.shape[1],))\n",
    "\n",
    "    x = Dense(64, activation=\"relu\")(input_age)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    output_age = Dense(1, activation=\"relu\")(x)\n",
    "\n",
    "    model_age = Model(inputs=input_age, outputs=output_age)\n",
    "    \n",
    "    return model_age\n",
    "\n",
    "model_age = build_model_age()\n",
    "model_age.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optim=Adam(learning_rate=0.01)\n",
    "model_age.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optim,\n",
    "                  metrics = ['accuracy'])\n",
    "model_age.fit(X_age, y, \n",
    "          validation_split=0.3,\n",
    "          epochs=30, \n",
    "          batch_size=16,\n",
    "          callbacks=[es]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inputs and Outputs of nii model as with age Model\n",
    "\n",
    "#model_nii = build_model_nii() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_nii = model_nii.input\n",
    "output_nii = model_nii.output\n",
    "\n",
    "#model_age = build_model_age() # comment-out to keep pre-trained weights not to start from scratch\n",
    "input_age = model_age.input\n",
    "output_age = model_age.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's combine the two streams of data and add two dense layers on top!\n",
    "inputs = [input_nii, input_age]\n",
    "\n",
    "combined = layers.concatenate([output_nii, output_age])\n",
    "\n",
    "x = Dense(16, activation=\"relu\")(combined)\n",
    "\n",
    "outputs = Dense(3, activation=\"softmax\")(x)\n",
    "\n",
    "model_combined = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_combined, \"multi_input_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combined.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = optim,\n",
    "                  metrics = ['accuracy'])\n",
    "es = EarlyStopping(patience=3, restore_best_weights = True)\n",
    "\n",
    "model_combined.fit(x=[X_nii, X_age], \n",
    "                   y=y,\n",
    "                   validation_split=0.3,\n",
    "                   epochs=50,\n",
    "                   batch_size=16,\n",
    "                   callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pleasedefine X_test and y_test before\n",
    "model_combined.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-tumor-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
